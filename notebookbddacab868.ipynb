{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoPauloRP/trilha-python-dio/blob/main/notebookbddacab868.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On30cqF6Tevm",
        "outputId": "0d0f641d-dd0a-416a-8a4b-b25048a3e837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ]
        }
      ],
      "source": [
        "# import the necessary packages\n",
        "!pip3 install imutils\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EMSYGR_xVRO"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1suWvSvVCfT",
        "outputId": "84c8dda5-b7aa-4709-fdc6-9d877f584fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
            "824887076/824887076 [==============================] - 19s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "_URL = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jbOId41Rcuo9",
        "outputId": "0d261ad6-a108-4f14-f3f9-3880bff825b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/cats_and_dogs.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "zip_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM2f8pstxVRb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip /root/.keras/datasets/cats_and_dogs.zip;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HevuKnEXVruN",
        "outputId": "78295226-6c4a-49b9-a1d7-c852db3345d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CDLA-Permissive-2.0.pdf   PetImages  'readme[1].txt'   sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nz_ioZvdaz9"
      },
      "outputs": [],
      "source": [
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "IMG_SIZE = 224\n",
        "INIT_LR = 1e-4\n",
        "BS = 256\n",
        "EPOCHS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIJH2pUfR6eV"
      },
      "outputs": [],
      "source": [
        "train = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip=True,\n",
        "vertical_flip=True,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "rotation_range=40, # Degree range for random rotations\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "fill_mode='nearest',\n",
        "validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l1ieNQojmSq"
      },
      "outputs": [],
      "source": [
        "dest = 'PetImages'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04fzH5yPxVRe"
      },
      "source": [
        "## Removing Corrupt images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCddBXGQYpsZ"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "from pathlib import Path\n",
        "from PIL import UnidentifiedImageError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G8z8_2lY1mz",
        "outputId": "2812a7fd-cebe-4e6c-dfb6-dff6d2166436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PetImages/Cat/666.jpg\n"
          ]
        }
      ],
      "source": [
        "path = Path('PetImages/Cat').rglob(\"*.jpg\")\n",
        "for img_p in path:\n",
        "    try:\n",
        "        img = PIL.Image.open(img_p)\n",
        "    except PIL.UnidentifiedImageError:\n",
        "            print(img_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZP3GET3aRnd",
        "outputId": "93d2b38a-0e87-434d-85c9-9a96d76a6019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "removed\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try: \n",
        "    os.remove(\"PetImages/Cat/666.jpg\")\n",
        "    print(\"removed\")\n",
        "except:\n",
        "  print(\"can't remove\") \n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5bTpl7vZVmT",
        "outputId": "b3e3c60f-d8be-4007-f4c2-6d00f655769c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PetImages/Dog/11702.jpg\n"
          ]
        }
      ],
      "source": [
        "path = Path('PetImages/Dog').rglob(\"*.jpg\")\n",
        "for img_p in path:\n",
        "    try:\n",
        "        img = PIL.Image.open(img_p)\n",
        "    except PIL.UnidentifiedImageError:\n",
        "            print(img_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYZufgxPZ9Bx",
        "outputId": "bed8e423-e954-4eeb-aa96-16bfee1ec430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "removed\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try: \n",
        "    os.remove(\"PetImages/Dog/11702.jpg\")\n",
        "    print(\"removed\")\n",
        "except:\n",
        "  print(\"can't remove\") \n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaArhk8pxVRi"
      },
      "source": [
        "## Train and Valid Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKnU841UiMBZ",
        "outputId": "b612aa97-0dc8-4cd8-85f9-535f9f47543e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "trainset = train.flow_from_directory(dest,\n",
        "target_size = (IMG_SIZE,IMG_SIZE),\n",
        "batch_size = BS,\n",
        "shuffle=False,\n",
        "seed=42,\n",
        "color_mode='rgb',\n",
        "subset = \"training\",\n",
        "class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckP5LXjhtvNz",
        "outputId": "c364c5dc-91eb-45ba-a154-3c5245f50591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4998 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validset = train.flow_from_directory(dest,\n",
        "target_size = (IMG_SIZE,IMG_SIZE),\n",
        "batch_size = BS,\n",
        "shuffle=False,\n",
        "seed=42,\n",
        "color_mode='rgb',\n",
        "subset = \"validation\",\n",
        "class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MillPWtddpYn"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxyOaOROxVRm"
      },
      "source": [
        "## Model Architecture - Xception!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi7Fr-0PiHND",
        "outputId": "518d5a24-1271-4149-9504-33fbfedc0120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n",
            "[INFO] compiling model...\n",
            "[INFO] training head...\n"
          ]
        }
      ],
      "source": [
        "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
        "# left off\n",
        "baseModel = Xception(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(IMG_SIZE,IMG_SIZE, 3)))\n",
        "\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(5, 5))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.8)(headModel)\n",
        "headModel = Dense(NUM_CLASSES, activation=\"softmax\")(headModel)\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "\n",
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam()\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jTvqpWyxVRn"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG3PtSgykHyQ",
        "outputId": "bae000ad-c69c-4641-b6e0-3a7c80d83813"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "79/79 [==============================] - 5178s 66s/step - loss: 0.4943 - accuracy: 0.7740 - val_loss: 0.3200 - val_accuracy: 0.8491\n",
            "Epoch 2/8\n",
            "79/79 [==============================] - 5176s 66s/step - loss: 0.3274 - accuracy: 0.8669 - val_loss: 0.2502 - val_accuracy: 0.8816\n",
            "Epoch 3/8\n",
            "79/79 [==============================] - 5139s 65s/step - loss: 0.2949 - accuracy: 0.8756 - val_loss: 0.2082 - val_accuracy: 0.9164\n",
            "Epoch 4/8\n",
            "79/79 [==============================] - 5185s 66s/step - loss: 0.2505 - accuracy: 0.8943 - val_loss: 0.2307 - val_accuracy: 0.8990\n",
            "Epoch 5/8\n",
            "79/79 [==============================] - 5131s 65s/step - loss: 0.2390 - accuracy: 0.9000 - val_loss: 0.1916 - val_accuracy: 0.9204\n",
            "Epoch 6/8\n",
            "79/79 [==============================] - 5170s 66s/step - loss: 0.2341 - accuracy: 0.9082 - val_loss: 0.1876 - val_accuracy: 0.9230\n",
            "Epoch 7/8\n",
            "79/79 [==============================] - 5132s 65s/step - loss: 0.2256 - accuracy: 0.9075 - val_loss: 0.1780 - val_accuracy: 0.9268\n",
            "Epoch 8/8\n",
            "79/79 [==============================] - 5146s 65s/step - loss: 0.2235 - accuracy: 0.9094 - val_loss: 0.1744 - val_accuracy: 0.9302\n"
          ]
        }
      ],
      "source": [
        "H = model.fit_generator(\n",
        "\ttrainset,\n",
        "  validation_data = validset,\n",
        "\tepochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "cm8O4a_63rFN",
        "outputId": "f6627854-678d-4b1f-db35-6c41e2057d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] saving mask detector model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-67437bb35142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# serialize the model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] saving mask detector model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat_dog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save('cat_dog', save_format=\"h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg3VPmMaxVRo"
      },
      "source": [
        "## Accuracy Loss Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DHfpNqekjHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "9b09e33c-b032-4afc-f62b-1171ca4ad118"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d8201e6b74a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the training loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EPOCHS' is not defined"
          ]
        }
      ],
      "source": [
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "plt.savefig('graph.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}